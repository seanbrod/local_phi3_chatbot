{
    "$schema": "https://microsoft.github.io/Olive/schema.json",
    "input_model":{
        "type": "PyTorchModelHandler",
        "config": {
            "hf_config": {
                "model_name": "finetuning/models/baseModels/",
                "task": "text-generation",
                "from_pretrained_args": {
                    "trust_remote_code": true
                }
            }
        }
    },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "config": {
                "accelerators": [
                    {
                        "device": "gpu",
                        "execution_providers": [
                            "CUDAExecutionProvider"
                        ]
                    }
                ]
            }
        }
    },
    "data_configs": [
        {
            "name": "dataset_default_train",
            "type": "HuggingfaceContainer",
            "params_config": {
                "data_name": "json", 
                "data_files":"finetuning/data/dataset01.json",
                "split": "train",
                "component_kwargs": {
                    "pre_process_data": {
                        "dataset_type": "corpus",
                        "text_cols": ["textContext","textInput", "output"],
                        "text_template": "<|system|>\n<|end|>\n<|user|>\nContext conversation:\n{textContext}\nMost recent user question:\n{textInput}<|end|>\n<|assistant|>\n{output}<|end|>",
                        "corpus_strategy": "join",
                        "source_max_len": 2048,
                        "pad_to_max_len": false,
                        "use_attention_mask": false
                    }
                }
            }
        }
    ],
    "passes": {
        "lora": {
            "type": "LoRA",
            "config": {
                "target_modules": [
                    "o_proj",
                    "qkv_proj"
                ],
                "lora_r": 64,
                "lora_alpha": 64,
                "lora_dropout": 0.1,
                "train_data_config": "dataset_default_train",
                "eval_dataset_size": 0.3,
                "training_args": {
                    "seed": 0,
                    "data_seed": 42,
                    "per_device_train_batch_size": 1,
                    "per_device_eval_batch_size": 1,
                    "gradient_accumulation_steps": 4,
                    "gradient_checkpointing": false,
                    "learning_rate": 0.0001,
                    "max_steps": 150,
                    "evaluation_strategy": "steps",
                    "adam_beta2": 0.999,
                    "max_grad_norm": 0.3
                }
            }
        },
        "merge": {
            "type": "MergeAdapterWeights"
        },
        "mb": {
            "type": "ModelBuilder",
            "config": {
                "precision": "int4"
            }
<<<<<<< HEAD
       
=======
        },
        "onnx_conversion": {
            "type": "OnnxConversion",
            "target_opset": 15 
        },
        "onnx_optimization": {
        "type": "OnnxOptimization",
        "config": {
            "optimization_level": "all"
>>>>>>> 1ec8e4ee4bfe1040beaae02efd2ef109b2f17dca
        }
    },
        "onnx_quantization": {
        "type": "OnnxQuantization",
        "config": {
            "quantization_method": "dynamic",
            "weight_type": "int8"
        }
    }
    },
    "pass_flows": [
  ["lora", "merge", "mb", "onnx_optimization"]
]
,
    "engine": {
        "cache_dir": "cache",
        "output_dir": "finetuning/models/tunedModels"
    }
}